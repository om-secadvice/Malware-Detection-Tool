import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
import pickle
import csv
import sys
import json
import random
from pathlib import Path
import joblib

from signature_description_analysis.signature_description_classifier import SignatureDescriptionClassifier
from behavior_api_stats_analysis.behavior_api_stats_classifier import ApiStatsClassifier
from network_protocol_count_analysis.network_protocol_count_classifier import NetworkProtocolCountClassifier

from extract_static_features import save_json_threaded_test
from static_features_model import test as static_feature_test
from strings_model import test as string_model_test

import warnings
warnings.filterwarnings("ignore")

BASE_PATH = os.getcwd()

DIR_PATH = '/mnt/D/C3iHackathonDataset/'
OUTPUT_DIR = 'merged'
META_DIR = 'meta'
STATIC_DATASET_DIR = {'static_features':"static_features_dataset", 'strings':"strings_dataset"}
BENIGN_CLASS = 0
MALWARE_CLASS = 1

DEFAULT_PREDICTION = '0.5'

LABEL_DICT = {BENIGN_CLASS : 'Benign', MALWARE_CLASS : 'Malware'}

def test_model():
    apiStatsClassifier = ApiStatsClassifier(BASE_PATH)
    networkProtocolCountClassifier = NetworkProtocolCountClassifier(BASE_PATH)
    signatureDescriptionClassifier = SignatureDescriptionClassifier(BASE_PATH)
    
    dynamic_files_list = []
    static_dir_list = []
    
    print()
    print('--------------------------------------------------------------')
    print('Creating Path List for Data')
    print('--------------------------------------------------------------')
    for path in Path(DIR_PATH).rglob('*.json'):
        path = str(path)
        dynamic_files_list.append(path)
      
    for path in Path(DIR_PATH).rglob('String.txt'):
        path = str(path)
        path = path.replace('/String.txt', '')
        static_dir_list.append(path)
        
    for path in Path(DIR_PATH).rglob('Structure_Info.txt'):
        path = str(path)
        path = path.replace('/Structure_Info.txt', '')
        static_dir_list.append(path)
    
    static_dir_list = list(set(static_dir_list))
    dynamic_files_list = sorted(dynamic_files_list)
    static_dir_list = sorted(static_dir_list)
    print('Done')
    
    
    print()
    print('--------------------------------------------------------------')
    print('Predicting using dynamic data')
    print('--------------------------------------------------------------')
    result = {}
    for file_path in dynamic_files_list:
        json_obj = json.load(open(file_path))
        
        try:
            apiStatsClassifierPred = apiStatsClassifier.predict(json_obj)[0]
        except:
            apiStatsClassifierPred = DEFAULT_PREDICTION
            print('apiStatsClassifierPred caused exception : ' + file_path)
        try:
            networkProtocolCountClassifierPred = networkProtocolCountClassifier.predict(json_obj)[0]
        except:
            networkProtocolCountClassifierPred = DEFAULT_PREDICTION
            print('networkProtocolCountClassifierPred caused exception : ' + file_path)
        try:
            signatureDescriptionClassifierPred = signatureDescriptionClassifier.predict(json_obj)[0]
        except:
            signatureDescriptionClassifierPred = DEFAULT_PREDICTION
            print('signatureDescriptionClassifierPred caused exception : ' + file_path)
           
        file_hash = file_path.split('/')[-1].replace('.json', '')
        
        result[file_hash] = {"APIStatsClassifier" : str(apiStatsClassifierPred), 
                             "NetworkProtocolCountClassifier" : str(networkProtocolCountClassifierPred),
                             "SignatureDescriptionClassifierPred" : str(signatureDescriptionClassifierPred)}
    print('Done')
    
    
    print()
    print('--------------------------------------------------------------')
    print('Predicting using static data')
    print('--------------------------------------------------------------')
    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    # Path(META_DIR).mkdir(parents=True, exist_ok=True)
    
    save_json_threaded_test(OUTPUT_DIR, META_DIR, static_dir_list)
    clf_static_frature = joblib.load(os.path.join(STATIC_DATASET_DIR['static_features'],'vote.pkl'))
    clf_string_model = joblib.load(os.path.join(STATIC_DATASET_DIR['strings'],'vote.pkl'))
    
    for static_dir in static_dir_list:
        file_hash = static_dir.split('/')[-1]
        json_file_path = os.path.join('merged', file_hash+'.json')
        
        try:
            prediction_static_frature = static_feature_test(clf_static_frature, json_file_path)[0]
        except:
            prediction_static_frature = DEFAULT_PREDICTION
            print('prediction_static_frature caused exception : ' + static_dir)
        try:
            prediction_string_model = string_model_test(clf_string_model, json_file_path)[0]   
        except:
            prediction_string_model = DEFAULT_PREDICTION
            print('prediction_string_model caused exception : ' + static_dir)
            
        if file_hash in result:
            result[file_hash]["StaticFeatureClassifier"] = str(prediction_static_frature)
            result[file_hash]["StringClassifier"] = str(prediction_string_model)
        else:
            result[file_hash] = { "StaticFeatureClassifier" :str(prediction_static_frature),
                                  "StringClassifier" : str(prediction_string_model) }
    print('Done')
    
    
    print()
    print('--------------------------------------------------------------')
    print('Creating final prediction')
    print('--------------------------------------------------------------')
    final_result = []
    for file_hash in result:
        pred_sum = 0.0
        for classifier in result[file_hash]:
            pred_sum += float(result[file_hash][classifier])
        if pred_sum / len(result[file_hash]) < 0.5:
            final_result.append([file_hash, 'Benign'])
        else:
            final_result.append([file_hash, 'Malware'])
    print('Done')
    
    
    print()
    print('--------------------------------------------------------------')
    print('Saving Classifier wise results')
    print('--------------------------------------------------------------')
    result = json.dumps(result, indent = 4) 
    with open("classifier_wise_result.json", "w") as outfile: 
        outfile.write(result)
    print('Done')
        
    print()
    print('--------------------------------------------------------------')
    print('Saving final result')
    print('--------------------------------------------------------------')
    with open('result.csv', 'w', newline='') as myfile:
        wr = csv.writer(myfile) #, quoting=csv.QUOTE_ALL
        wr.writerows(final_result)
    print('Done')
    
    
if __name__ == '__main__':
    DIR_PATH = sys.argv[1]
    test_model()
        