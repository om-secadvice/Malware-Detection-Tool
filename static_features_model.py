import codecs
import os
import sys
import glob
import json
import numpy as np
import scipy as scp
import random
import joblib
import csv
from pathlib import Path
from sklearn.feature_extraction.text import HashingVectorizer
from sklearn.preprocessing import StandardScaler,MaxAbsScaler,RobustScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.feature_selection import SelectFromModel
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier,VotingClassifier,AdaBoostClassifier,GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC,SVC
from sklearn.neural_network import MLPClassifier
RANDOM_SEED = 50
def set_random():
    random.seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)

# Only required for training
INPUT_DIR = '/mnt/D/C3iHackathonDataset/static/merged'
META_DIR = '/mnt/D/C3iHackathonDataset/static/meta'
DATASET_DIR = {'static_features':"static_features_dataset"}
ALL_DLL_CHARACTERISTICS = ''
ALL_IMAGE_FILE_HEADER_FLAGS = ''

def get_features_from_json(file_path):
    ALL_DLL_CHARACTERISTICS = json.load(codecs.open(os.path.join(META_DIR,'all_dll_characteristics.json')))
    ALL_IMAGE_FILE_HEADER_FLAGS = json.load(codecs.open(os.path.join(META_DIR,'all_image_file_header_flags.json')))
    report_json = json.load(codecs.open(file_path,'r'))
    name = report_json['name']
    label = report_json['class_label']
    features = [int(report_json['is_packed_or_corrupt']),
            report_json['no_of_standard_sections'],
            report_json['no_of_non_standard_sections'],
            report_json['size_of_code'],
            report_json['size_of_initialized_data'],
            report_json['size_of_image'],
            report_json['max_entropy'],
            report_json['no_of_writable_sections'],
#                 report['imported_api'],
            int(report_json['version_info_presence'])] + list(report_json['image_directory_entry_size'].values())
    image_header_flags = dict([(i,0) for i in ALL_IMAGE_FILE_HEADER_FLAGS])
    dll_characteristics = dict([(i,0) for i in ALL_DLL_CHARACTERISTICS])
    for flag in report_json['image_file_header_flags']:
            image_header_flags[flag] = 1
    for flag in report_json['dll_characteristics']:
            dll_characteristics[flag] = 1

    # Final feature vector
    features += list(image_header_flags.values()) + list(dll_characteristics.values())
    return name,label,features

def save_static_features_dataset():
    set_random()
    
    
    files = glob.glob(os.path.join(INPUT_DIR,'*'))
    names = {}
    X = []
    y = []

    for file in files:
        name,label,features = get_features_from_json(file)       
                
        names[name] = len(names)
        X.append(features)
        y.append(label)


    X = np.array(X)
    y = np.array(y)
    print('X:',X.shape)
    print('y:',y.shape)

    # Create directory for saving strings dataset and models
    Path(DATASET_DIR['static_features']).mkdir(parents=True, exist_ok=True)
    print('Saving Dataset')
    np.savez(os.path.join(DATASET_DIR['static_features'],'dataset.npz'), X = X, y=y)
    json.dump(names,codecs.open(os.path.join(DATASET_DIR['static_features'],'names.json'),'w'))

def load_static_features_dataset():
    set_random()
    # Load names
    names = json.load(codecs.open(os.path.join(DATASET_DIR['static_features'],'names.json'),'r'))

    # Load dataset
    data = np.load(os.path.join(DATASET_DIR['static_features'],'dataset.npz'),allow_pickle=True)
    X,y = data['X'],data['y']

    return names,X,y

def get_data_from_list(X,y,names:dict,list_file):
    current_names = {}
    Xres = []
    yres = []
    with open(list_file, newline='') as f:
        reader = csv.reader(f)
        training_data = list(reader)
    for file in training_data:
        name = file[0]
        if name in names:
            current_names[name] = len(current_names)
            Xres.append(X[names[name],:])
            yres.append(y[names[name]])
            
    return Xres, yres, current_names
             
def train():
    set_random()
    names,X,y = load_static_features_dataset() 
    Xtrain, ytrain , namestrain = get_data_from_list(X, y, names, 'training_data.csv')
    
    clf = Pipeline([
        ('scaler', MaxAbsScaler()),
        ('classification', VotingClassifier(estimators=[('DT',DecisionTreeClassifier()),
                                            ('MLP',MLPClassifier(max_iter=1000)),
                                            ('RF',RandomForestClassifier(n_jobs=-1)),
                                            ('AdaB',AdaBoostClassifier()),
                                            ('GB',GradientBoostingClassifier())],voting='soft',))])

    print('Training model')    
    clf.fit(Xtrain,ytrain)
    joblib.dump(clf,os.path.join(DATASET_DIR['static_features'],'vote.pkl'))
    return clf

def validation(clf,list_file = 'validation_data.csv'):
    set_random()
    names,X,y = load_static_features_dataset() 
    Xval, yval , namesval = get_data_from_list(X, y, names, list_file)
    ypred = clf.predict(Xval)
    print('Confusion Matrix')
    print(confusion_matrix(yval,ypred))
    print(classification_report(yval,ypred))

def test(clf,json_file_path, INPUT_DIRP='merged', META_DIRP='meta'):
    set_random()
    global INPUT_DIR, META_DIR, ALL_DLL_CHARACTERISTICS, ALL_IMAGE_FILE_HEADER_FLAGS
    INPUT_DIR = INPUT_DIRP
    META_DIR = META_DIRP
    ALL_DLL_CHARACTERISTICS = json.load(codecs.open(os.path.join(META_DIR,'all_dll_characteristics.json')))
    ALL_IMAGE_FILE_HEADER_FLAGS = json.load(codecs.open(os.path.join(META_DIR,'all_image_file_header_flags.json')))
    _,_,x = get_features_from_json(json_file_path)
    return clf.predict([x])
    
# save_static_features_dataset()
# clf = train()
# clf = joblib.load(os.path.join(DATASET_DIR['static_features'],'vote.pkl'))
# validation(clf)

# print(test(clf,'/mnt/D/C3iHackathonDataset/static/merged/002efac668aa6e1a35b9b489f2be520e7cb45acd4aa441fd6fd1ebd78e5be519.json'))

