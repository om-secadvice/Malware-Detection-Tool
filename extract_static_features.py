from enum import Enum, auto

# DIRECTORIES_TO_SCAN = ['/mnt/D/C3iHackathonDataset/static/Benign']
# MALWARE_DIRS = ['/mnt/D/C3iHackathonDataset/static/Malware/'+i for i in ['Virus','Worm','Backdoor','Trojan','TrojanDropper','TrojanDownloader']]
# DIRECTORIES_TO_SCAN.extend(MALWARE_DIRS)

STRUCTURE_INFO_FILE = 'Structure_Info.txt'
STRINGS_FILE = 'String.txt'

class Report:
    def __init__(self,name):
        self.name = name
        self.strings_file = None
        self.is_packed_or_corrupt = False
        self.no_of_standard_sections = 0
        self.no_of_non_standard_sections = 0
        self.image_file_header_flags = []
        self.size_of_code = 0
        self.size_of_initialized_data = 0
        self.size_of_image = 0
        self.dll_characteristics = []
        self.sections = {}
        self.max_entropy = 0
        self.no_of_writable_sections = 0
        self.image_directory_entry_size = {}
        self.imported_api = []
        self.version_info_presence = False
        self.class_label = 0
    def __str__(self):
        return json.dumps(self.__dict__)

import codecs
import glob
import os
import sys
import json
from pathlib import Path
import threading
NO_OF_THREADS = os.cpu_count()
OUTPUT_DIR = '/mnt/D/C3iHackathonDataset/static/merged'
META_DIR = '/mnt/D/C3iHackathonDataset/static/meta'
STANDARD_SECTIONS = set({'.text','.data','.rdata','.pdata','.reloc','.rsrc','.bss','.cormeta','.debug','.debug$F','.debug$P','.debug$S','.debug$T','.drective','.edata','.idata','.idlsym','.sbss','.sdata','.srdata','.sxdata','.tls','.vsdata','.xdata'})
ALL_IMAGE_FILE_HEADER_FLAGS = dict.fromkeys(range(NO_OF_THREADS),set({}))
ALL_IMPORTED_API = dict.fromkeys(range(NO_OF_THREADS),set({}))
ALL_DLLCHARACTERISTICS = dict.fromkeys(range(NO_OF_THREADS),set({}))
# Create output directory

named_dirs = []

TEST_MODE = False

# Scan through benign and Malware directories containing static info
#for scan_dir in DIRECTORIES_TO_SCAN:
    # Prepare list of hash-named folders of PE
#    named_dirs.extend(glob.glob(os.path.join(scan_dir,'*')))
# named_dirs = named_dirs[1002:1052]
TOTAL_FILES = len(named_dirs)
FILES_PER_THREAD = int(TOTAL_FILES/NO_OF_THREADS)

def save_json_reports(thread_id):
        global named_dirs
        global TOTAL_FILES
        global FILES_PER_THREAD
        global TEST_MODE
        TOTAL_FILES = len(named_dirs)
        FILES_PER_THREAD = int(TOTAL_FILES/NO_OF_THREADS)
        start = thread_id*FILES_PER_THREAD
        end = (thread_id+1)*FILES_PER_THREAD
        if thread_id == NO_OF_THREADS - 1:
            end = TOTAL_FILES
        print('Thread started:',thread_id,start,'-->',end)
        for file_idx in range(start,end):
            named_dir = named_dirs[file_idx]
            # File hash is same as folder name
            file_name = named_dir.split('/')[-1]
            report = Report(file_name)
            # print(file_count,file_name)
            # Get PE structure information file stream and strings information file stream for parsing
            struct_info_file = codecs.open(os.path.join(named_dir,STRUCTURE_INFO_FILE),'r',encoding='utf-8',errors='ignore')
            report.strings_file = os.path.join(named_dir,STRINGS_FILE)
#             strings_file = codecs.open(os.path.join(named_dir,STRINGS_FILE),'r',encoding='utf-8',errors='ignore')
#             report.strings.extend([i.strip() for i in strings_file.readlines()])
            


            lines = struct_info_file.readlines()
            lines = [line.strip() for line in lines]
            len_lines = len(lines)
            if len_lines == 0:
                # print(scan_dir,file_name)
                continue

            ctr = 0
            for i in range(ctr,len_lines):
                line = lines[i]
                
                if '----------DOS_HEADER----------' not in line:
                    if 'packed' in line or 'corrupt' in line or 'error' in line:
                        report.is_packed_or_corrupt = True
                else:
                    ctr += 29 # File Header starts here 
                    break
                ctr += 1

            # Read fields from IMAGE_FILE_HEADER
            # NoOfSections 
            while 'NumberOfSections:' not in lines[ctr]:
                ctr += 1
            report.no_of_standard_sections = int(lines[ctr].split(' ')[-1],16)
            report.no_of_non_standard_sections = 0
            
            # Flags
            while 'Flags:' not in lines[ctr]:
                ctr += 1
            report.image_file_header_flags.extend(lines[ctr].replace(', ',' ').split(' ')[1:])
            ctr += 2


            # Read fields from IMAGE_FILE_HEADER
            # SizeOfCode
            ctr += 6
            report.size_of_code = int(lines[ctr].split(' ')[-1],16)
            
            # SizeOfInitializedData
            ctr += 1
            report.size_of_initialized_data = int(lines[ctr].split(' ')[-1],16)

            # SizeOfImage
            ctr += 15
            report.size_of_image = int(lines[ctr].split(' ')[-1],16)

            # DllCharacteristics
            ctr += 11
            report.dll_characteristics.extend(lines[ctr].replace(', ',' ').split(' ')[1:])
            ctr += 2
            # Use meta from train mode
            if not TEST_MODE:
                ALL_DLLCHARACTERISTICS[thread_id] |= set(report.dll_characteristics)

            # Read from IMAGE_SECTION_HEADER array
            while '----------Directories----------' != lines[ctr]:

                if '[IMAGE_SECTION_HEADER]' in lines[ctr]:
                    section={}

                    # Section Name
                    ctr += 1
                    section_name = lines[ctr].split(' ')[-1]
                    if section_name not in STANDARD_SECTIONS:
                        report.no_of_standard_sections -= 1
                        report.no_of_non_standard_sections += 1
                    
                    # SizeOfRawData
                    ctr += 5
                    section['size_of_raw_data'] = int(lines[ctr].split(' ')[-1],16)
                    
                    # Flags
                    ctr += 7
                    section['flags'] = lines[ctr].replace(', ',' ').split(' ')[1:]
                    if 'IMAGE_SCN_MEM_WRITE' in section['flags']:
                        report.no_of_writable_sections += 1

                    # Entropy
                    ctr += 1
                    section['entropy'] = float(lines[ctr].split(' ')[1])

                    report.max_entropy = max(report.max_entropy,section['entropy'])    
                    report.sections[section_name] = section
                ctr += 1
            ctr += 2

            
            # Read presence(size>0) from IMAGE_DATA_DIRECTORY array
            ORDERED_IMAGE_DIRECTORY_ENTRY_TYPES = ['EXPORT','IMPORT','RESOURCE','EXCEPTION','SECURITY',
                                                    'BASERELOC','DEBUG','COPYRIGHT','GLOBALPTR','TLS',
                                                    'LOAD_CONFIG','BOUND_IMPORT','IAT','DELAY_IMPORT',
                                                    'COM_DESCRIPTOR','RESERVED']
            # print(lines[ctr+2])
            for entry in range(len(ORDERED_IMAGE_DIRECTORY_ENTRY_TYPES)):
                try:
                    report.image_directory_entry_size[ORDERED_IMAGE_DIRECTORY_ENTRY_TYPES[entry]] = int(lines[ctr+2].split(' ')[-1],16)
                except:
                    report.image_directory_entry_size[ORDERED_IMAGE_DIRECTORY_ENTRY_TYPES[entry]] = 0
                    
                finally:
                    ctr += 3
            
            

            # Read imported method names from array of IMAGE_IMPORT_DESCRIPTOR
            while lines[ctr] != 'None':
                if lines[ctr] == '----------Version Information----------':
                    report.version_info_presence = True
                if lines[ctr] == '[IMAGE_IMPORT_DESCRIPTOR]':
                    ctr += 8
                    while lines[ctr] != '':
                        report.imported_api.append(lines[ctr].split(' ')[0].split('.')[-1])
                        ctr += 1
                ctr += 1   

            if 'Malware' in named_dir:
                report.class_label = 1
            
            # Use meta from train mode
            if not TEST_MODE:
                global ALL_IMAGE_FILE_HEADER_FLAGS
                global ALL_IMPORTED_API
                ALL_IMAGE_FILE_HEADER_FLAGS[thread_id] |= set(report.image_file_header_flags)
                ALL_IMPORTED_API[thread_id] |= set(report.imported_api)
            
            global OUTPUT_DIR
            report_json = json.loads(str(report))
            assert report.no_of_non_standard_sections >= 0
            assert report.no_of_standard_sections >= 0
            json.dump(report_json,open(os.path.join(OUTPUT_DIR,file_name+'.json'),'w'))
            # all_reports.append(report_json)
        


        


def global_dump():
    global ALL_IMAGE_FILE_HEADER_FLAGS
    global ALL_IMPORTED_API
    global ALL_DLLCHARACTERISTICS
    global META_DIR
    Path(META_DIR).mkdir(parents=True, exist_ok=True)
    APIS = set()
    FLAGS = set()
    CHARACTERISTICS = set()
    for tid in range(NO_OF_THREADS):
        APIS |= ALL_IMPORTED_API[tid]
        del ALL_IMPORTED_API[tid]
        FLAGS |= ALL_IMAGE_FILE_HEADER_FLAGS[tid]
        del ALL_IMAGE_FILE_HEADER_FLAGS[tid]
        CHARACTERISTICS |= ALL_DLLCHARACTERISTICS[tid]
        del ALL_DLLCHARACTERISTICS[tid]
        
    json.dump(list(FLAGS),open(os.path.join(META_DIR,'all_image_file_header_flags.json'),'w'))
    json.dump(list(APIS),open(os.path.join(META_DIR,'all_imported_api.json'),'w'))
    json.dump(list(CHARACTERISTICS),open(os.path.join(META_DIR,'all_dll_characteristics.json'),'w'))
    print('ALL_IMAGE_FILE_HEADER_FLAGS:',len(FLAGS))
    print('ALL_IMPORTED_API:',len(APIS))
    print('ALL_DLLCHARACTERISTICS:',len(CHARACTERISTICS))

def save_json_threaded():
    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    threads = []
    for i in range(NO_OF_THREADS):
        thd = threading.Thread(target=save_json_reports,args=(i,))
        thd.start()
        threads.append(thd)

    for thd in threads:
        thd.join()
    
    global_dump()
    
def save_json_threaded_test(OUTPUT_DIRP, META_DIRP, named_dirsP):
    global OUTPUT_DIR
    global META_DIR
    global named_dirs
    global TEST_MODE
    TEST_MODE = True
    OUTPUT_DIR = OUTPUT_DIRP
    META_DIR = META_DIRP
    named_dirs = named_dirsP
    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    threads = []
    for i in range(NO_OF_THREADS):
        thd = threading.Thread(target=save_json_reports,args=(i,))
        thd.start()
        threads.append(thd)

    for thd in threads:
        thd.join()
    
#     global_dump()
# all_reports = save_json_reports()
# # print(json.dumps(all_reports[0],indent=4))
# global_dump()
# print('Total Files:',TOTAL_FILES)
# save_json_threaded()
