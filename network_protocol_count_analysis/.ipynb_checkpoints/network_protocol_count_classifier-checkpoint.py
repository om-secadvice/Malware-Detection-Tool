import json
import os
import csv
import pickle
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import numpy as np
np.random.seed(12)

ANALYSIS_PER_CATEGORY_THRESHOLD = 10

class NetworkProtocolCountClassifier:
    def __init__(self, BASE_PATH, DIR_PATH='', DYNAMIC_DIR='', BENIGN_DIR='', MALWARE_DIR=''):
        self.BASE_PATH = os.path.join(BASE_PATH, 'network_protocol_count_analysis')
        self.DIR_PATH = DIR_PATH
        self.DYNAMIC_DIR = DYNAMIC_DIR
        self.BENIGN_DIR = BENIGN_DIR
        self.MALWARE_DIR = MALWARE_DIR
        self.BENIGN_CLASS = 0
        self.MALWARE_CLASS = 1
        if DYNAMIC_DIR != '' and MALWARE_DIR != '':
            self.MALWARE_CATEGORIES = os.listdir(os.path.join(DIR_PATH, DYNAMIC_DIR, MALWARE_DIR))
        self.protocols_considered = ['dead_hosts', 'http', 'icmp', 'irc', 'mitm', 'smtp', 'tcp','tls', 'udp']
        self.clf = pickle.load(open(os.path.join(self.BASE_PATH, 'trained_network_protocol_classifier'), 'rb'))
#         self.protocols_considered = ['dead_hosts', 'http', 'http_ex', 'https_ex', 'icmp', 'irc', 'mitm', 'smtp', 'smtp_ex', 'tcp','tls', 'udp']
        
    def create_protocol_count_feature_matrix(self):
        print('Creating api stats feature matrix')
        malware_feature_dict = {}
        for category in self.MALWARE_CATEGORIES:
            print(category)
            for json_file in os.listdir(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.MALWARE_DIR, category)):#[:ANALYSIS_PER_CATEGORY_THRESHOLD]:
                json_obj = json.load(open(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.MALWARE_DIR, category, json_file)))
                row = [0] * len(self.protocols_considered)
                network = json_obj['network']
                for index, protocol in enumerate(self.protocols_considered):
                    row[index] = len(network[protocol])
                
                malware_feature_dict[json_file.split('.')[0]] = row
        json_object = json.dumps(malware_feature_dict, indent = 4) 
        with open(os.path.join(self.BASE_PATH, "malware_feature_dict.json"), "w") as outfile: 
            outfile.write(json_object)

        print('Saved Malware Feature Matrix')

        benign_feature_dict = {}
        for json_file in os.listdir(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.BENIGN_DIR)):#[:ANALYSIS_PER_CATEGORY_THRESHOLD]:
            json_obj = json.load(open(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.BENIGN_DIR, json_file)))
            row = [0] * len(self.protocols_considered)
            network = json_obj['network']
            for index, protocol in enumerate(self.protocols_considered):
                row[index] = len(network[protocol])
            
            benign_feature_dict[json_file.split('.')[0]] = row
        json_object = json.dumps(benign_feature_dict, indent = 4) 
        with open(os.path.join(self.BASE_PATH, "benign_feature_dict.json"), "w") as outfile: 
            outfile.write(json_object)
        print('Saved Benign Feature Matrix')


    def train_val_split(self, VAL_SPLIT=0.25):
        benign_feature_dict = json.load(open(os.path.join(self.BASE_PATH, 'benign_feature_dict.json')))
        malware_feature_dict = json.load(open(os.path.join(self.BASE_PATH, 'malware_feature_dict.json')))

        with open('training_data.csv', newline='') as f:
            reader = csv.reader(f)
            training_data = list(reader)            
        with open('validation_data.csv', newline='') as f:
            reader = csv.reader(f)
            validation_data = list(reader)

        X_train, y_train, X_val, y_val = [], [], [], []
        training_hashes = []
        validation_hashes = []
        
        for data in training_data:
            if data[0] in malware_feature_dict:
                training_hashes.append(data[0])
                X_train.append(malware_feature_dict[data[0]])
                y_train.append(self.MALWARE_CLASS)
            elif data[0] in benign_feature_dict:
                training_hashes.append(data[0])
                X_train.append(benign_feature_dict[data[0]])
                y_train.append(self.BENIGN_CLASS)
        
        for data in validation_data:
            if data[0] in malware_feature_dict:
                validation_hashes.append(data[0])
                X_val.append(malware_feature_dict[data[0]])
                y_val.append(self.MALWARE_CLASS)
            elif data[0] in benign_feature_dict:
                validation_hashes.append(data[0])
                X_val.append(benign_feature_dict[data[0]])
                y_val.append(self.BENIGN_CLASS)
        
        X_train = np.array(X_train)
        y_train = np.array(y_train)
        X_val = np.array(X_val)
        y_val = np.array(y_val)

        print('Train: ', X_train.shape[0])
        print('Val: ', X_val.shape[0])
        
        with open(os.path.join(self.BASE_PATH, "training_hashes"), "w") as outfile:
            outfile.write("\n".join(training_hashes))
            
        with open(os.path.join(self.BASE_PATH, "validation_hashes"), "w") as outfile:
            outfile.write("\n".join(validation_hashes))
        
        return X_train, y_train, X_val, y_val
    
    def train_classifier(self, classifier):
        print('Training classifier')
        #logreg = LogisticRegression(C=10.0)
        X_train, y_train, X_val, y_val = self.train_val_split()
        classifier.fit(X_train, y_train)
        y_pred = classifier.predict(X_val)

        print('---------------------------------------------------------------------------------')
        print('Accuracy')
        print('---------------------------------------------------------------------------------')
        print(classifier.score(X_val, y_val))

        print('---------------------------------------------------------------------------------')
        print('Confusion Matrix')
        print('---------------------------------------------------------------------------------')
        print(confusion_matrix(y_val, y_pred))

        print('---------------------------------------------------------------------------------')
        print('Classification Report')
        print('---------------------------------------------------------------------------------')
        print(classification_report(y_val, y_pred, labels=[0, 1]))
        
    def train(self, clf):
        self.clf = clf
        self.create_protocol_count_feature_matrix()
        self.train_classifier(clf)
    
    def save_trained_model(self):
        pickle.dump(self.clf, open(os.path.join(self.BASE_PATH, 'trained_network_protocol_classifier'), 'wb'))
        print('Model saved successfully.')     
             
    def predict(self, json_obj):
#         json_obj = json.load(open(path))
        row = [0] * len(self.protocols_considered)
        network = json_obj['network']
        for index, protocol in enumerate(self.protocols_considered):
            row[index] = len(network[protocol])
            
        return self.clf.predict([row])
    