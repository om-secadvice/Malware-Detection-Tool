import json
import os
import csv
import pickle
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import numpy as np
np.random.seed(12)

ANALYSIS_PER_CATEGORY_THRESHOLD = 10

class ApiStatsClassifier:
    def __init__(self, BASE_PATH, DIR_PATH='', DYNAMIC_DIR='', BENIGN_DIR='', MALWARE_DIR=''):
        self.BASE_PATH = os.path.join(BASE_PATH, 'behavior_api_stats_analysis')
        self.DIR_PATH = DIR_PATH
        self.DYNAMIC_DIR = DYNAMIC_DIR
        self.BENIGN_DIR = BENIGN_DIR
        self.MALWARE_DIR = MALWARE_DIR
        self.BENIGN_CLASS = 0
        self.MALWARE_CLASS = 1
        if DYNAMIC_DIR != '' and MALWARE_DIR != '':
            self.MALWARE_CATEGORIES = os.listdir(os.path.join(DIR_PATH, DYNAMIC_DIR, MALWARE_DIR))
        self.clf = pickle.load(open(os.path.join(self.BASE_PATH, 'trained_api_stat_classifier'), 'rb'))
        with open(os.path.join(self.BASE_PATH, "final_uniq_api_stats"), "r") as f:
            self.uniq_api_stats = f.read().splitlines()
        self.uniq_api_stat_dict = json.load(open(os.path.join(self.BASE_PATH, 'uniq_api_stat_dict.json')))
        
        
    def extract_unique_api_stats_malware(self):
        print('Extracting unique api stats for malware')
        malware_uniq_api_stats = []
        for category in self.MALWARE_CATEGORIES:
            print(category)
            for json_file in os.listdir(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.MALWARE_DIR, category)):#[:ANALYSIS_PER_CATEGORY_THRESHOLD]:
                json_obj = json.load(open(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.MALWARE_DIR, category, json_file)))
                api_stats = json_obj['behavior']['apistats']
                for api in api_stats:
                    malware_uniq_api_stats.append(api)
                
        malware_uniq_api_stats = list(set(malware_uniq_api_stats))
        with open(os.path.join(self.BASE_PATH, "malware_uniq_api_stats"), "w") as outfile:
            outfile.write("\n".join(malware_uniq_api_stats))
        print('Saved unique malware api stats at ' + 'malware_uniq_api_stats')

    def extract_unique_api_stats_benign(self):
        print('Extracting unique api stats for benign')
        benign_uniq_api_stats = []
        for json_file in os.listdir(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.BENIGN_DIR)):#[:ANALYSIS_PER_CATEGORY_THRESHOLD]:
            json_obj = json.load(open(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.BENIGN_DIR, json_file)))
            api_stats = json_obj['behavior']['apistats']
            for api in api_stats:
                benign_uniq_api_stats.append(api)

        benign_uniq_api_stats = sorted(list(set(benign_uniq_api_stats)))
        with open(os.path.join(self.BASE_PATH, "benign_uniq_api_stats"), "w") as outfile:
            outfile.write("\n".join(benign_uniq_api_stats))
        print('Saved unique benign api stats at ' + 'benign_uniq_api_stats')
        
    def create_combined_unique_api_stats(self):
        print('Creating unique combined api stats')
        malware_uniq_api_stats = []
        with open(os.path.join(self.BASE_PATH, "malware_uniq_api_stats"), "r") as infile:
            malware_uniq_api_stats = infile.readlines()
        malware_uniq_api_stats = list(map(lambda s: s.strip(), malware_uniq_api_stats))

        benign_uniq_api_stats = []
        with open(os.path.join(self.BASE_PATH, "benign_uniq_api_stats"), "r") as infile:
            benign_uniq_api_stats = infile.readlines()
        benign_uniq_api_stats = list(map(lambda s: s.strip(), benign_uniq_api_stats))

        uniq_api_stats = sorted(list(set(malware_uniq_api_stats + benign_uniq_api_stats)))
        
        self.uniq_api_stats = uniq_api_stats
        
        with open(os.path.join(self.BASE_PATH, "final_uniq_api_stats"), "w") as outfile:
            outfile.write("\n".join(uniq_api_stats))
        
        print('Total unique api stats : ' + str(len(uniq_api_stats)))
        
    def create_api_stats_feature_matrix(self):
        print('Creating api stats feature matrix')
        malware_feature_dict = {}
        for category in self.MALWARE_CATEGORIES:
            print(category)
            for json_file in os.listdir(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.MALWARE_DIR, category)):#[:ANALYSIS_PER_CATEGORY_THRESHOLD]:
                json_obj = json.load(open(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.MALWARE_DIR, category, json_file)))
                row = [0] * len(self.uniq_api_stats)
                api_stats = json_obj['behavior']['apistats']
                for api in api_stats:
                    row[self.uniq_api_stats.index(api)] = 1
                
                malware_feature_dict[json_file.split('.')[0]] = row
        json_object = json.dumps(malware_feature_dict, indent = 4) 
        with open(os.path.join(self.BASE_PATH, "malware_feature_dict.json"), "w") as outfile: 
            outfile.write(json_object)
        print('Saved Malware Feature Matrix')

        benign_feature_dict = {}
        for json_file in os.listdir(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.BENIGN_DIR)):#[:ANALYSIS_PER_CATEGORY_THRESHOLD]:
            json_obj = json.load(open(os.path.join(self.DIR_PATH, self.DYNAMIC_DIR, self.BENIGN_DIR, json_file)))
            row = [0] * len(self.uniq_api_stats)
            api_stats = json_obj['behavior']['apistats']
            for api in api_stats:
                row[self.uniq_api_stats.index(api)] = 1
            
            benign_feature_dict[json_file.split('.')[0]] = row
        json_object = json.dumps(benign_feature_dict, indent = 4) 
        with open(os.path.join(self.BASE_PATH, "benign_feature_dict.json"), "w") as outfile: 
            outfile.write(json_object)
        print('Saved Benign Feature Matrix')


    def train_val_split(self):
        benign_feature_dict = json.load(open(os.path.join(self.BASE_PATH, 'benign_feature_dict.json')))
        malware_feature_dict = json.load(open(os.path.join(self.BASE_PATH, 'malware_feature_dict.json')))

        with open('training_data.csv', newline='') as f:
            reader = csv.reader(f)
            training_data = list(reader)            
        with open('validation_data.csv', newline='') as f:
            reader = csv.reader(f)
            validation_data = list(reader)

        X_train, y_train, X_val, y_val = [], [], [], []
        training_hashes = []
        validation_hashes = []
        
        for data in training_data:
            if data[0] in malware_feature_dict:
                training_hashes.append(data[0])
                X_train.append(malware_feature_dict[data[0]])
                y_train.append(self.MALWARE_CLASS)
            elif data[0] in benign_feature_dict:
                training_hashes.append(data[0])
                X_train.append(benign_feature_dict[data[0]])
                y_train.append(self.BENIGN_CLASS)
        
        for data in validation_data:
            if data[0] in malware_feature_dict:
                validation_hashes.append(data[0])
                X_val.append(malware_feature_dict[data[0]])
                y_val.append(self.MALWARE_CLASS)
            elif data[0] in benign_feature_dict:
                validation_hashes.append(data[0])
                X_val.append(benign_feature_dict[data[0]])
                y_val.append(self.BENIGN_CLASS)
        
        X_train = np.array(X_train)
        y_train = np.array(y_train)
        X_val = np.array(X_val)
        y_val = np.array(y_val)

        print('Train: ', X_train.shape[0])
        print('Val: ', X_val.shape[0])
        
        with open(os.path.join(self.BASE_PATH, "training_hashes"), "w") as outfile:
            outfile.write("\n".join(training_hashes))
            
        with open(os.path.join(self.BASE_PATH, "validation_hashes"), "w") as outfile:
            outfile.write("\n".join(validation_hashes))
        
        return X_train, y_train, X_val, y_val
    
    def train_classifier(self, classifier):
        print('Training classifier')
        #logreg = LogisticRegression(C=10.0)
        X_train, y_train, X_val, y_val = self.train_val_split()
        classifier.fit(X_train, y_train)
        y_pred = classifier.predict(X_val)

        print('---------------------------------------------------------------------------------')
        print('Accuracy')
        print('---------------------------------------------------------------------------------')
        print(classifier.score(X_val, y_val))

        print('---------------------------------------------------------------------------------')
        print('Confusion Matrix')
        print('---------------------------------------------------------------------------------')
        print(confusion_matrix(y_val, y_pred))

        print('---------------------------------------------------------------------------------')
        print('Classification Report')
        print('---------------------------------------------------------------------------------')
        print(classification_report(y_val, y_pred, labels=[0, 1]))
        
    def uniq_api_stat_dict(self):
        uniq_api_stat_dict = {}
        for index, uni_api_stat in enumerate(self.uniq_api_stats):
            uniq_api_stat_dict[uni_api_stat] = index
        json_object = json.dumps(uniq_api_stat_dict, indent = 4) 
        with open(os.path.join(self.BASE_PATH, "uniq_api_stat_dict.json"), "w") as outfile: 
            outfile.write(json_object)
            
    def train(self, clf):
        self.clf = clf
        self.extract_unique_api_stats_malware()
        self.extract_unique_api_stats_benign()
        self.create_combined_unique_api_stats()
        self.uniq_api_stat_dict()
        self.create_api_stats_feature_matrix()
        self.train_classifier(clf)
        
    def save_trained_model(self):
        pickle.dump(self.clf, open(os.path.join(self.BASE_PATH, 'trained_api_stat_classifier'), 'wb'))
        print('Model saved successfully.')  
         
    def predict(self, json_obj):
#         json_obj = json.load(open(path))
        row = [0] * len(self.uniq_api_stats)
        api_stats = json_obj['behavior']['apistats']
        for api in api_stats:
            row[self.uniq_api_stat_dict[api]] = 1
        
        return self.clf.predict([row])
        
        